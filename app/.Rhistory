# Step 1: Finding the minising cluster lables
z <- apply(p, 1, which.max)
# Step 2: Recalibrate parameters
for(j in c(1:k))
{
mu[j, ] <- colMeans(data[z == j, ])
X <- cbind(data[z==j, 1] - mu[j, 1], data[z==j, 2] - mu[j, 2])
Sigma[[j]] <- (t(X) %*% X)/sum(z==j)
}
}
# Return
return(list(mu = mu, z = z, Sigma=Sigma))
}
mu <- c(2, -2, -2, -2, -3, 1)
dim(mu) <- c(3, 2)
# Set all covariance matrices to identity matrices
Sigma <- list(matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2))
result <- kMeansFull(cdata3, mu, Sigma)
par(mfrow = c(1,2))
plot(cdata3, pch = 16, asp = 1, xlim=c(-4, 4), ylim=c(-4,4), main="Initial centers for cdata3")
points(mu[, 1], mu[, 2], pch = 21, col = "black", bg = RGB)
plot(cdata3, pch = 16, asp = 1, xlim=c(-4,4), ylim=c(-4,4), type = "p", col = c("red", "green", "blue")[result$z], main="Final clusters and centers\nfor cdata3")
points(result$mu[, 1], result$mu[, 2], pch = 21, col = "black", bg = RGB, lwd=2)
mu <- runif(6, -4, 4)
#mu <- c(2, -2, -2, -2, -3, 1)
dim(mu) <- c(3, 2)
# Set all covariance matrices to identity matrices
Sigma <- list(matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2))
result <- kMeansFull(cdata3, mu, Sigma)
par(mfrow = c(1,2))
plot(cdata3, pch = 16, asp = 1, xlim=c(-4, 4), ylim=c(-4,4), main="Initial centers for cdata3")
points(mu[, 1], mu[, 2], pch = 21, col = "black", bg = RGB)
plot(cdata3, pch = 16, asp = 1, xlim=c(-4,4), ylim=c(-4,4), type = "p", col = c("red", "green", "blue")[result$z], main="Final clusters and centers\nfor cdata3")
points(result$mu[, 1], result$mu[, 2], pch = 21, col = "black", bg = RGB, lwd=2)
mu <- runif(6, -4, 4)
#mu <- c(2, -2, -2, -2, -3, 1)
dim(mu) <- c(3, 2)
# Set all covariance matrices to identity matrices
Sigma <- list(matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2))
result <- kMeansFull(cdata3, mu, Sigma)
par(mfrow = c(1,2))
plot(cdata3, pch = 16, asp = 1, xlim=c(-4, 4), ylim=c(-4,4), main="Initial centers for cdata3")
points(mu[, 1], mu[, 2], pch = 21, col = "black", bg = RGB)
plot(cdata3, pch = 16, asp = 1, xlim=c(-4,4), ylim=c(-4,4), type = "p", col = c("red", "green", "blue")[result$z], main="Final clusters and centers\nfor cdata3")
points(result$mu[, 1], result$mu[, 2], pch = 21, col = "black", bg = RGB, lwd=2)
#mu <- runif(6, -4, 4)
mu <- c(2, -2, -2, -2, -3, 1)
dim(mu) <- c(3, 2)
# Set all covariance matrices to identity matrices
Sigma <- list(matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2))
result <- kMeansFull(cdata3, mu, Sigma)
par(mfrow = c(1,2))
plot(cdata3, pch = 16, asp = 1, xlim=c(-4, 4), ylim=c(-4,4), main="Initial centers for cdata3")
points(mu[, 1], mu[, 2], pch = 21, col = "black", bg = RGB)
plot(cdata3, pch = 16, asp = 1, xlim=c(-4,4), ylim=c(-4,4), type = "p", col = c("red", "green", "blue")[result$z], main="Final clusters and centers\nfor cdata3")
points(result$mu[, 1], result$mu[, 2], pch = 21, col = "black", bg = RGB, lwd=2)
rep(2, 3)
generateDataFull <- function(data, mu, z, Sigma){
# Now that you have good estimates for mu and z find the approximate fractions of individual
# clusters lambda[i] = pr[z=i].
lambda <- rep(NA, 3)
lambda[1] <- mean(z==1)
lambda[2] <- mean(z==2)
lambda[3] <- mean(z==3)
names(lambda) <- RGB
# generate data according to mixture distribution
n <- nrow(data)
x <- runif(n)
#z.new <- (x <= lambda[1]) * 1 + (lambda[1] < x) * (x <= lambda[1] + lambda[2]) * 2 + (lambda[1] + lambda[2] < x) * 3
z.new <- 1 + (x < lambda[1]) + (x < lambda[1] + lambda[2])
data.new <- data.frame(x = rep(NA, n), y = rep(NA, n))
for(i in c(1:n))
{
data.new[i, 1] <- rmvnorm(1, mean = mu[z.new[i],1], sigma = Sigma[[z.new[i]]])
data.new[i, 2] <- rmvnorm(1, mean = mu[z.new[i],2], sigma = Sigma[[z.new[i]]])
}
return(list(data.new=data.new, z=z.new))
}
gendata <- generateDataFull(cdata3, result$mu, result$z, result$Sigma)
mu=result$mu
mu
mu[1,1]
generateDataFull <- function(data, mu, z, Sigma){
# Now that you have good estimates for mu and z find the approximate fractions of individual
# clusters lambda[i] = pr[z=i].
lambda <- rep(NA, 3)
lambda[1] <- mean(z==1)
lambda[2] <- mean(z==2)
lambda[3] <- mean(z==3)
names(lambda) <- RGB
# generate data according to mixture distribution
n <- nrow(data)
x <- runif(n)
#z.new <- (x <= lambda[1]) * 1 + (lambda[1] < x) * (x <= lambda[1] + lambda[2]) * 2 + (lambda[1] + lambda[2] < x) * 3
z.new <- 1 + (x < lambda[1]) + (x < lambda[1] + lambda[2])
data.new <- data.frame(x = rep(NA, n), y = rep(NA, n))
for(i in c(1:n))
{
data.new[i, ] <- rmvnorm(1, mean = mu[z.new[i],], sigma = Sigma[[z.new[i]]])
}
return(list(data.new=data.new, z=z.new))
}
gendata <- generateDataFull(cdata3, result$mu, result$z, result$Sigma)
gendata <- generateDataFull(cdata3, result$mu, result$z, result$Sigma)
par(mfcol=c(1,2))
plot(cdata3, pch = 16, asp = 1, xlim=c(-4,4), ylim=c(-4,4), main="cdata3")
plot(gendata$data.new, pch = 16, asp = 1, xlim=c(-4,4), ylim=c(-4,4), main="Generated data")
array <- readJPEG("forest.jpg")
dim(array)
?jpeg
head(array)
array
array[,,1]
img <- readJPEG("forest.jpg")
imgDm <- dim(img)
# Assign RGB channels to data frame
imgRGB <- data.frame(
x = rep(1:imgDm[2], each = imgDm[1]),
y = rep(imgDm[1]:1, imgDm[2]),
R = as.vector(img[,,1]),
G = as.vector(img[,,2]),
B = as.vector(img[,,3])
)
head(imgRGB)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, warnings=FALSE)
library(knitr)
library(car)
library(rgl)
library(jpeg)
library(mvtnorm)
library(ggplot2)
setwd("/Users/Liis/Desktop/DOK/K_2017/MachineLearning/EX11")
img <- readJPEG("forest.jpg")
imgDm <- dim(img)
# Assign RGB channels to data frame
# Treat each pixel as a tree dimensional vector
imgRGB <- data.frame(
x = rep(1:imgDm[2], each = imgDm[1]),
y = rep(imgDm[1]:1, imgDm[2]),
R = as.vector(img[,,1]),
G = as.vector(img[,,2]),
B = as.vector(img[,,3])
)
# Plot the image
ggplot(data = imgRGB, aes(x = x, y = y)) +
geom_point(colour = rgb(imgRGB[c("R", "G", "B")])) +
labs(title = "Forest") +
xlab("x") + ylab("y")
head(imgRGB[, c("R", "G", "B")])
mu <- runif(6, -4, 4)
dim(mu) <- c(3, 2)
# Set all covariance matrices to identity matrices
Sigma <- list(matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2), matrix(c(1, 0, 0, 1), 2, 2))
result <- kMeansFull(imgRGB[, c("R", "G", "B")], mu, Sigma)
mu
data=imgRGB[, c("R", "G", "B")]
head(data)
mu
mu <- runif(9, -4, 4)
dim(mu) <- c(3, 3)
mu
dmvnorm(data[1,], mean=mu[1, ])
dmvnorm(data[1,], mean=mu[1, ], sigma=Sigma[[1]])
matrix(c(1, 0, 0, 0,1,0,0,0,1), 3, 3)
Sigma <- list(matrix(c(1, 0, 0, 0, 1, 0, 0, 0, 1), 3, 3), matrix(c(1, 0, 0, 0, 1, 0, 0, 0, 1), 3, 3), matrix(c(1, 0, 0, 0, 1, 0, 0, 0, 1), 3, 3))
Sigma
result <- kMeansFull(imgRGB[, c("R", "G", "B")], mu, Sigma)
head(data)
summary(data)
mu <- runif(9, 0, 1)
dim(mu) <- c(3, 3)
# Set all covariance matrices to identity matrices
Sigma <- list(matrix(c(1, 0, 0, 0, 1, 0, 0, 0, 1), 3, 3), matrix(c(1, 0, 0, 0, 1, 0, 0, 0, 1), 3, 3), matrix(c(1, 0, 0, 0, 1, 0, 0, 0, 1), 3, 3))
result <- kMeansFull(imgRGB[, c("R", "G", "B")], mu, Sigma)
kMeansFullImg <- function(data, mu, Sigma)
{
k <- nrow(mu)
n <- nrow(data)
for(t in c(1:10))
{
# Find probabilities
p <- matrix(NA, n, k)
for(j in c(1:k)){
for(i in c(1:n))
{
p[i, j] <- dmvnorm(x=data[i, ], mean = mu[j, ], sigma = Sigma[[j]])
}
}
# Step 1: Finding the minising cluster lables
z <- apply(p, 1, which.max)
# Step 2: Recalibrate parameters
for(j in c(1:k))
{
mu[j, ] <- colMeans(data[z == j, ])
X <- cbind(data[z==j, 1] - mu[j, 1], data[z==j, 2] - mu[j, 2])
Sigma[[j]] <- (t(X) %*% X)/sum(z==j)
}
}
# Return
return(list(mu = mu, z = z, Sigma=Sigma))
}
result <- kMeansFullImg(imgRGB[, c("R", "G", "B")], mu, Sigma)
kMeansFullImg <- function(data, mu, Sigma)
{
k <- nrow(mu)
n <- nrow(data)
for(t in c(1:5))
{
print(t)
# Find probabilities
p <- matrix(NA, n, k)
for(j in c(1:k)){
for(i in c(1:n))
{
p[i, j] <- dmvnorm(x=data[i, ], mean = mu[j, ], sigma = Sigma[[j]])
}
}
# Step 1: Finding the minising cluster lables
z <- apply(p, 1, which.max)
# Step 2: Recalibrate parameters
for(j in c(1:k))
{
mu[j, ] <- colMeans(data[z == j, ])
X <- cbind(data[z==j, 1] - mu[j, 1], data[z==j, 2] - mu[j, 2])
Sigma[[j]] <- (t(X) %*% X)/sum(z==j)
}
}
# Return
return(list(mu = mu, z = z, Sigma=Sigma))
}
result <- kMeansFullImg(imgRGB[, c("R", "G", "B")], mu, Sigma)
head(data)
dim(data)
k <- nrow(mu)
k
n <- nrow(data)
n
p <- matrix(NA, n, k)
for(j in c(1:k)){
for(i in c(1:n))
{
p[i, j] <- dmvnorm(x=data[i, ], mean = mu[j, ], sigma = Sigma[[j]])
}
}
p <- matrix(NA, n, k)
for(i in c(1:n))
{
for(j in c(1:k)){
p[i, j] <- dmvnorm(x=data[i, ], mean = mu[j, ], sigma = Sigma[[j]])
}
}
p <- matrix(NA, n, k)
for(i in c(1:n))
{
for(j in c(1:k)){
print(i)
p[i, j] <- dmvnorm(x=data[i, ], mean = mu[j, ], sigma = Sigma[[j]])
}
}
?kmeans
kClusters <- 3
kMeans <- kmeans(imgRGB[, c("R", "G", "B")], centers = kClusters)
kColours <- rgb(kMeans$centers[kMeans$cluster,])
ggplot(data = imgRGB, aes(x = x, y = y)) +
geom_point(colour = kColours) +
labs(title = paste("k-Means Clustering of", 3, "Colours")) +
xlab("x") + ylab("y")
kClusters <- 5
kMeans <- kmeans(imgRGB[, c("R", "G", "B")], centers = kClusters)
kColours <- rgb(kMeans$centers[kMeans$cluster,])
ggplot(data = imgRGB, aes(x = x, y = y)) +
geom_point(colour = kColours) +
labs(title = paste("k-Means Clustering of", 3, "Colours")) +
xlab("x") + ylab("y")
kClusters <- 5
kMeans <- kmeans(imgRGB[, c("R", "G", "B")], centers = kClusters)
kColours <- rgb(kMeans$centers[kMeans$cluster,])
ggplot(data = imgRGB, aes(x = x, y = y)) +
geom_point(colour = kColours) +
labs(title = paste("k-Means clustering of", kClusters, "colours")) +
xlab("x") + ylab("y")
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, warnings=FALSE)
library(knitr)
library(car)
library(rgl)
library(jpeg)
library(mvtnorm)
library(ggplot2)
setwd("/Users/Liis/Desktop/DOK/K_2017/MachineLearning/EX11")
img <- readJPEG("forest.jpg")
imgDm <- dim(img)
# Assign RGB channels to data frame
# Treat each pixel as a tree dimensional vector
imgRGB <- data.frame(
x = rep(1:imgDm[2], each = imgDm[1]),
y = rep(imgDm[1]:1, imgDm[2]),
R = as.vector(img[,,1]),
G = as.vector(img[,,2]),
B = as.vector(img[,,3])
)
# Plot the image
ggplot(data = imgRGB, aes(x = x, y = y)) +
geom_point(colour = rgb(imgRGB[c("R", "G", "B")])) +
labs(title = "Forest") +
xlab("x") + ylab("y")
kable(head(imgRGB))
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, warnings=FALSE)
library(knitr)
library(car)
library(rgl)
library(jpeg)
library(mvtnorm)
library(ggplot2)
library(scatterplot3d)
setwd("/Users/Liis/Desktop/DOK/K_2017/MachineLearning/EX11")
scatterplot3d(imgRGB[,"R"], imgRGB[,"G"], imgRGB[,"B"], color=kColours)
kClusters <- 5
kMeans <- kmeans(imgRGB[, c("R", "G", "B")], centers = kClusters)
kColours <- rgb(kMeans$centers[kMeans$cluster,])
ggplot(data = imgRGB, aes(x = x, y = y)) + geom_point(colour = kColours) +
labs(title = paste("k-Means clustering of", kClusters, "colours")) +
xlab("x") + ylab("y")
scatterplot3d(imgRGB[,"R"], imgRGB[,"G"], imgRGB[,"B"], color=kColours)
scatterplot3d(imgRGB[,"R"], imgRGB[,"G"], imgRGB[,"B"], color=kColours, pch=16)
library(rvest)
library(readr)
library(stringr)
library(wordcloud)
main_url <- "http://tqhq.ee/forum/viewboard.php?bid=4&page="
pages <- 1:206
library(dplyr)
res <- NULL
for (page in pages){
url <- paste0(main_url,page)
html = read_html(url, encoding="UTF-8")
pealkirjad = html %>% html_nodes('td[align="left"]') %>% html_text()
pealkirjad = pealkirjad[pealkirjad != "\u00A0" & pealkirjad != "Topics"]
pealkirjad = unlist(lapply(pealkirjad, function(x) str_replace(x, "Pages:.*", "")))
pealkirjad = unlist(lapply(pealkirjad, function(x) trimws(x)))
res = rbind(res, data.frame(teema=pealkirjad))
}
res$teema <- as.character(res$teema)
words <- stack(tapply(res$teema, rownames(res), function(x) scan(text=x, what='')))
words$values <- tolower(words$values)
words$values <- str_replace_all(words$values,"[[:punct:]]","")
words$values <- str_replace_all(words$values,"[[:digit:]]","")
words <- words[words$values!="",]
subdata <- words %>% filter(nchar(values)>1) %>% group_by(values) %>% mutate(count = n())  %>% distinct(values, .keep_all = TRUE)
wc <- wordcloud(subdata$values, subdata$count, scale=c(2.5,.5), min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(8,"Dark2"), random.color=FALSE, )
words <- stack(tapply(res$teema, rownames(res), function(x) scan(text=x, what='')))
words$values <- tolower(words$values)
words$values <- str_replace_all(words$values,"[[:punct:]]","")
words <- words[words$values!="",]
subdata <- words %>% filter(nchar(values)>1) %>% group_by(values) %>% mutate(count = n())  %>% distinct(values, .keep_all = TRUE)
wc <- wordcloud(subdata$values, subdata$count, scale=c(2.5,.5), min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(8,"Dark2"), random.color=FALSE, )
a="2009a"
str_replace_all(a,"[[:digit:]]","")
res$teema <- as.character(res$teema)
words <- stack(tapply(res$teema, rownames(res), function(x) scan(text=x, what='')))
words$values <- tolower(words$values)
words$values <- str_replace_all(words$values,"[[:punct:]]","")
words$values <- str_replace_all(words$values,"[[:digit:]]","")
words <- words[words$values!="",]
subdata <- words %>% filter(nchar(values)>1) %>% group_by(values) %>% mutate(count = n())  %>% distinct(values, .keep_all = TRUE)
wc <- wordcloud(subdata$values, subdata$count, scale=c(2.5,.5), min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(8,"Dark2"), random.color=FALSE, )
head(subdata)
subdata[subdata$values=="v8",]
a=["v8", "2008"]
a=c("v8", "2008")
str_replace_all(a,"[[:digit:]]","")
res$teema <- as.character(res$teema)
words <- stack(tapply(res$teema, rownames(res), function(x) scan(text=x, what='')))
words$values <- tolower(words$values)
words$values <- str_replace_all(words$values,"[[:punct:]]","")
words <- words[!(words$values %in% c("2006", "2007"),]
words <- words[words$values!="",]
subdata <- words %>% filter(nchar(values)>1) %>% group_by(values) %>% mutate(count = n())  %>% distinct(values, .keep_all = TRUE)
wc <- wordcloud(subdata$values, subdata$count, scale=c(2.5,.5), min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(8,"Dark2"), random.color=FALSE, )
wc <- wordcloud(subdata$values, subdata$count, min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(8,"Dark2"), random.color=FALSE, )
words$values %in% c("2006", "2007")
words[words$values==2006,]
words <- stack(tapply(res$teema, rownames(res), function(x) scan(text=x, what='')))
words$values <- tolower(words$values)
words$values <- str_replace_all(words$values,"[[:punct:]]","")
words <- words[!(words$values %in% c(2006, 2007)),]
words <- words[words$values!="",]
subdata <- words %>% filter(nchar(values)>1) %>% group_by(values) %>% mutate(count = n())  %>% distinct(values, .keep_all = TRUE)
wc <- wordcloud(subdata$values, subdata$count, min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(8,"Dark2"), random.color=FALSE, )
wc <- wordcloud(subdata$values, subdata$count, min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(6,"Dark2"), random.color=FALSE, )
wc <- wordcloud(subdata$values, subdata$count, min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(6,"Dark3"), random.color=FALSE, )
wc <- wordcloud(subdata$values, subdata$count, min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(6,"Dark1"), random.color=FALSE, )
?brewer.pal
wc <- wordcloud(subdata$values, subdata$count, min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(6,"Set2"), random.color=FALSE, )
wc <- wordcloud(subdata$values, subdata$count, min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, colors=brewer.pal(6,"Set2"), random.color=TRUE)
wc <- wordcloud(subdata$values, subdata$count, min.freq = 10, max.words=200, random.order=TRUE, rot.per=0.3, random.color=TRUE)
30/100
sqrt(50)
sqrt(50)*0.3
100/30
sqrt(50)*100/30
sqrt(50)*1.3
sqrt(50)*0.03
sqrt(50)*3
sqrt(100)
sqrt(1000)-sqrt(5)
45/29.38671
45/29.38671*sqrt(1000)
45/29.38671*sqrt(5)
5-3.424101
45/29.38671*sqrt(1000)+1.575899
shiny::runApp('Desktop/DOK/K_2017/Andmete_visualiseerimine/Projekt/sajv_projekt/app')
library(plotly)
runApp('Desktop/DOK/K_2017/Andmete_visualiseerimine/Projekt/sajv_projekt/app')
runApp('Desktop/DOK/K_2017/Andmete_visualiseerimine/Projekt/sajv_projekt/app')
head(data)
head(vectors)
vectors <- read.csv("../data/vecs2.csv")
getwd()
setwd("/Users/Liis/Desktop/DOK/K_2017/Andmete_visualiseerimine/Projekt/sajv_projekt/app/")
vectors <- read.csv("../data/vecs2.csv")
data=vectors
pca = prcomp(data[,c(2:101,209:211)], center = TRUE, scale. = TRUE) #viimased 3 sisse?
pca.fortify <- fortify(pca)
pca.dat <- cbind(pca.fortify, group=data$allikas, headline=data$cleaned_pealkiri)
p <- ggplot(pca.dat) +
geom_point(aes(x=PC1, y=PC2, fill=group, col=group, text=headline), position = position_jitter(w = 0.1, h = 0.1), size=1, alpha=0.6) + theme_bw() + scale_fill_manual(values = colors, breaks=names(colors)) + theme(legend.title=element_blank()) +
scale_color_manual(values = colors, breaks=names(colors)) + coord_fixed()
p
colors <- c("#ffc820", "#0054a6", "#cf0007", "#00adee") # delfi, err, ohtuleht, postimees
allikad <- c("delfi", "err", "ohtuleht", "postimees")
names(colors) <- allikad
ilus_allikad <- c("Delfi", "ERR", "Ã•htuleht", "Postimees")
p <- ggplot(pca.dat) +
geom_point(aes(x=PC1, y=PC2, fill=group, col=group, text=headline), position = position_jitter(w = 0.2, h = 0.2), size=1, alpha=0.6) + theme_bw() + scale_fill_manual(values = colors, breaks=names(colors)) + theme(legend.title=element_blank()) +
scale_color_manual(values = colors, breaks=names(colors)) + coord_fixed()
p
pl <- ggplotly(p, tooltip = c("text"))  %>% layout(legend = list(x = 0, y = 100, orientation = 'h'))
pl
p
pl$layout.aspectratio
pl <- ggplotly(p, tooltip = c("text"))  %>% layout(legend = list(x = 0, y = 100, orientation = 'h'), autosize = F)
pl
?coord_fixed
p <- ggplot(pca.dat) +
geom_point(aes(x=PC1, y=PC2, fill=group, col=group, text=headline), position = position_jitter(w = 0.2, h = 0.2), size=1, alpha=0.6) + theme_bw() + scale_fill_manual(values = colors, breaks=names(colors)) + theme(legend.title=element_blank()) +
scale_color_manual(values = colors, breaks=names(colors)) + coord_fixed(ratio=1)
pl <- ggplotly(p, tooltip = c("text"))  %>% layout(legend = list(x = 0, y = 100, orientation = 'h'), autosize = F)
pl
p
pl <- ggplotly(p, tooltip = c("text"))  %>% layout(legend = list(x = 0, y = 100, orientation = 'h'), aspectmode="data")
pl
pl <- ggplotly(p, tooltip = c("text"))  %>% layout(legend = list(x = 0, y = 100, orientation = 'h'), aspectmode="cube")
pl
pl <- ggplotly(p, tooltip = c("text"))  %>% layout(aspectmode="cube")
pl
p <- ggplot(pca.dat) +
geom_point(aes(x=PC1, y=PC2, fill=group, col=group, text=headline), position = position_jitter(w = 0.2, h = 0.2), size=1, alpha=0.6) + theme_bw() + scale_fill_manual(values = colors, breaks=names(colors)) +
theme(aspect.ratio=1, legend.title=element_blank()) +
scale_color_manual(values = colors, breaks=names(colors))
p
pl <- ggplotly(p, tooltip = c("text"))
pl
p
pl
pl <- ggplotly(p, tooltip = c("text"))  %>% layout(legend = list(x = 0, y = 100, orientation = 'h')) %>%  coord_fix()
pl
p <- ggplot(pca.dat) +
geom_point(aes(x=PC1, y=PC2, fill=group, col=group, text=headline), position = position_jitter(w = 0.2, h = 0.2), size=1, alpha=0.6) + theme_bw() + scale_fill_manual(values = colors, breaks=names(colors)) +
theme(aspect.ratio=1, legend.title=element_blank()) +
scale_color_manual(values = colors, breaks=names(colors))
pl <- ggplotly(p, tooltip = c("text"))  %>% layout(legend = list(x = 0, y = 100, orientation = 'h')) %>%  coord_fix()
pl
pl <- ggplotly(p, tooltip = c("text"))  %>% layout(legend = list(x = 0, y = 100, orientation = 'h'))
pl
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?renderPlotly
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
cleandata <- read.csv("../data/meediadata_cleaned1.csv")
head(cleandata)
runApp()
vectors <- read.csv("../data/vecs_final2.csv")
head(vectors)
head(vectors[,c(2:101)])
head(vectors[,c(2:102)])
runApp()
pl$x$data[[1]]
str(pl$x$data[[1]])
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
vectors <- read.csv("../data/vecs_final2.csv")
data=vectors
data$summa = sum(data[,c(2:101)])
head(data)
tail(data)
summary(data$summa)
str(data)
runApp()
